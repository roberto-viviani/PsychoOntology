---
title: "Supplementary results B (replication)"
author: "Roberto Viviani, University of Innsbruck"
date: "2024-04-22"
output:
  word_document: default
  pdf_document: default
---

We present here the results of the OpenAI model of the main text with the other best performing model, gecko. Our intent is to verify the replicability of results. We also present the results obtained with the universal sentence encoder (USE), a model trained with a simpler architecture, to show the improvements in replicability obtained with the newer models. Details on the models and their source are in the methods section of the main text.

The results are presented side-by-side to facilitate comparison. Note that semantic distance is not a quantitative measure that can be compared per se across models. The adequate terms of comparison are the test statistics showing differences in mean semantic distances or their association with participant responses.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.dim = c(12,5.2))
library(ggplot2)
library(ggpubr)

library(dplyr)
library(tidyr)

# utilities to decode embeddings
source("embedding_utilities.R") 

getassocmx <- function(embeddings, scales) {
# compute data.frame with embedding distance and response correlations
# The response correlations are given by scales, which may be loaded from
# scales_data_extended_csv or scales_data.csv
  
  #when we read the scales, we drop the extranumerary NEO items
  cormx <- cor(as.matrix(scales |> select(starts_with("NEOFFI"))), 
      as.matrix(scales |> select(starts_with("PID5BF"))))
  cordata <- data.frame(corrs = as.vector(cormx), cosdist = as.vector(embeddings$cdist),
                        typeNEO = embeddings$NEO$type, 
                        typePID = rep(embeddings$PID$type, each = nrow(embeddings$NEO)),
                        itemNEO = embeddings$NEO$itemID, 
                        itemPID = rep(embeddings$PID$itemID, each = nrow(embeddings$NEO)))
  # typos in the dataset
  cordata[cordata$typePID == "eccentrictiy", "typePID"] <- "eccentricity" 
  cordata[cordata$typePID == "intimicy avoidance", "typePID"] <- "intimacy avoidance"
  cordata$traitPID <- traits[cordata$typePID]
  
  # create a group ordering for PID facets that respects traits
  library(forcats)
  traits <- as.integer(as.factor(cordata$traitPID))
  traits <- traits * -20 + as.integer(as.factor(cordata$typePID))
  cordata$typePID <- fct_reorder(cordata$typePID, traits)

  cordata
}

#we read the participant scores (only PID and NEO scores)
#the data are not available in the repository because of data privacy constraints
scales <- read.csv("scales_data_extended.csv")

# load embeddings from models
cordata_1 <- getassocmx(loadEmbeddings("embeddings_openAI_large_de.csv"), scales)
cordata_2 <- getassocmx(loadEmbeddings("embeddings_gecko_de.csv"), scales)
cordata_3 <- getassocmx(loadEmbeddings("embeddings_univSentEncoder_de.csv"), scales)
models <- c("OpenAI", "gecko", "USE")

# plotting utilities
source("plot_utilities.R")

# stat utilities
source("stats_utilities.R")

pidtraits <- c("PIDAnankastia", "PIDAntagonism", "PIDDetachment",
               "PIDDisinhibition", "PIDNegativeAffect", "PIDPsychoticism")
traitnames <- c("Anankastia", "Antagonism", "Detachment",
               "Disinhibition", "NegativeAffect", "Psychoticism")

```

### General NEO subscale associations

We first compare replicability at sub-scale level (an easier task as the semantic distances are averaged within sub-scales).

```{r}
p1 <- ggplot(
  cordata_1 |> group_by(typeNEO, traitPID) |> summarize(corr = mean(corrs), dist = mean(cosdist)),
  aes(y = corr, x = dist)) + 
  geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE) +
  geom_point(aes(color = typeNEO, shape = traitPID), alpha = 0.8, size = 4) +
  geom_smooth(aes(color = typeNEO), method = "lm", se = FALSE) + 
  scale_color_viridis_d() + 
  labs(color = "NEO trait", shape = "PID domain") + 
  xlab("semantic distance") + ylab("avg correlation") + theme_classic()

p2 <- ggplot(
  cordata_2 |> group_by(typeNEO, traitPID) |> summarize(corr = mean(corrs), dist = mean(cosdist)),
  aes(y = corr, x = dist)) + 
  geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE) +
  geom_point(aes(color = typeNEO, shape = traitPID), alpha = 0.8, size = 4) +
  geom_smooth(aes(color = typeNEO), method = "lm", se = FALSE) + 
  scale_color_viridis_d() + 
  labs(color = "NEO trait", shape = "PID domain") + 
  xlab("semantic distance") + ylab("avg correlation") + theme_classic()

p3 <- ggplot(
  cordata_3 |> group_by(typeNEO, traitPID) |> summarize(corr = mean(corrs), dist = mean(cosdist)),
  aes(y = corr, x = dist)) + 
  geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE) +
  geom_point(aes(color = typeNEO, shape = traitPID), alpha = 0.8, size = 4) +
  geom_smooth(aes(color = typeNEO), method = "lm", se = FALSE) + 
  scale_color_viridis_d() + 
  labs(color = "NEO trait", shape = "PID domain") + 
  xlab("semantic distance") + ylab("avg correlation") + theme_classic()

ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")

```



We plotted below the relationship between response correlations and semantic distance at the level of individual item pairs (a more difficult task). The cloud of points, each of which is a pair of items, resembles a wedge pointing to the right. At semantic distances of 0.7 or higher, there was very little systematic correlation between responses. However, there were also several cases of item pairs that the language model judged to have semantic distances of 0.4 or less but gave rise to no correlation in the responses of participants. These are items pairs located in the middle of the left part of the wedge. Here, the model appears to fail to detect the semantic distance of items whose answers showed no correlation. Furthermore, for conscientiousness the correlation does not stop at zero at large semantic distances but becomes negative (see text for further analysis).

```{r main, message = FALSE}

p1 <- ggplot(cordata_1, aes(cosdist, corrs, color = typeNEO)) +  
  geom_smooth(aes(group = typeNEO), method = "lm", se = T, alpha = 0.1) + 
  geom_point(shape=21, alpha = 0.5) +
  scale_color_viridis_d(name = "NEO trait") + labs(title = models[1]) +
  xlab('semantic distance') + ylab('responses correlation') + theme_classic()
p2 <- ggplot(cordata_2, aes(cosdist, corrs, color = typeNEO)) +  
  geom_smooth(aes(group = typeNEO), method = "lm", se = T, alpha = 0.1) + 
  geom_point(shape=21, alpha = 0.5) +
  scale_color_viridis_d(name = "NEO trait") + labs(title = models[2]) +
  xlab('semantic distance') + ylab('responses correlation') + theme_classic()
p3 <- ggplot(cordata_3, aes(cosdist, corrs, color = typeNEO)) +  
  geom_smooth(aes(group = typeNEO), method = "lm", se = T, alpha = 0.1) + 
  geom_point(shape=21, alpha = 0.5) +
  scale_color_viridis_d(name = "NEO trait") + labs(title = models[3]) +
  xlab('semantic distance') + ylab('responses correlation') + theme_classic()

ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")

```

Note here that the universal sentence encoder puts more item pairs in the middle of the plot on the left border, where semantic distance is low and correlation is about zero. This may be an index of failure in assessing the semantic distinctness of items to which participants gave responses that were not correlated. In low performing models, we saw the wedge-formed cloud loose the wedge form, and become an formless blob. In this respect, gecko appears to perform best even if the significance of the association between response correlations and semantic distances is slightly lower than open AI in the logistic binomial model (see main text). As a result, extraversion becomes negatively associated with the PIDS rather than being flat as in the open AI model. Openness to experience remains flat.

### Neuroticism

Here and in all subsequent sections, printouts of stats table are ordered with OpenAI first, gecko second, and USE third.

```{r neuroticism, message = FALSE}
plotdata_1 <- filter(cordata_1, typeNEO == "Neuroticism")
plotdata_2 <- filter(cordata_2, typeNEO == "Neuroticism")
plotdata_3 <- filter(cordata_3, typeNEO == "Neuroticism")

# test of variance to see if semantic distance differs in PID traits
print("Omnibus test of differences in distances NEO/PID")
chi1 <- anovadist(plotdata_1)$Chisq[2]
chi2 <- anovadist(plotdata_2)$Chisq[2]
chi3 <- anovadist(plotdata_3)$Chisq[2]

p1 <- bxplf(plotdata_1) + labs(title = models[1]) + 
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi1, digits = 4))))
p2 <- bxplf(plotdata_2) + labs(title = models[2]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi2, digits = 4))))
p3 <- bxplf(plotdata_3) + labs(title = models[3]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi3, digits = 4))))

mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of association between NEO correlations and semantic distance
print("Test of association between NEO correlations and semantic distances")
corrs <- pearscorr(scales, "NEOneuro", pidtraits)
corrs$traitPID <- stringi::stri_sub(row.names(corrs), from = 4)
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_1, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_2, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_3, corrs, by = "traitPID")))

pf <- function(plotdata) {
  p <- baseplot(plotdata)
  p <- addneoline(p, plotdata, "NegativeAffect")
  p <- addneoline(p, plotdata, "Detachment")
  p <- addneoline(p, plotdata, "Disinhibition")
  p <- addneoline(p, plotdata, "Antagonism")
  p <- p + labs(text = element_text(size = 16)) +
    geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE)
  p  
}
# the correlations are the same in all plotdata variables
crbound <- quantile(abs(plotdata_1$corrs), probs = 0.975)
csbound <- function(plotdata) {q <- quantile(plotdata$cosdist, probs=1-0.975); q}

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1, 
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3,
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of slopes significance in above plots
print("Tests of significance of slopes (prediction of response associations from semantic similarity")
pearscorr(plotdata_1 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_2 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_3 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1,
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3, 
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

```

We see here that the LLMs, OpenAI and gecko, provided similar results. The universal sentence encoder could not give accurate assessments of the relationship between semantic similarity and response correlations with the PID domains. One can also see that, the scale-level assessment of semantic similarity gives no significant differences, in contrast with the other two models.

### Extraversion

```{r extraversion, message = FALSE}
plotdata_1 <- filter(cordata_1, typeNEO == "Extraversion")
plotdata_2 <- filter(cordata_2, typeNEO == "Extraversion")
plotdata_3 <- filter(cordata_3, typeNEO == "Extraversion")

# test of variance to see if semantic distance differs in PID traits
print("Omnibus test of differences in distances NEO/PID")
chi1 <- anovadist(plotdata_1)$Chisq[2]
chi2 <- anovadist(plotdata_2)$Chisq[2]
chi3 <- anovadist(plotdata_3)$Chisq[2]

p1 <- bxplf(plotdata_1) + labs(title = models[1]) + 
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi1, digits = 4))))
p2 <- bxplf(plotdata_2) + labs(title = models[2]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi2, digits = 4))))
p3 <- bxplf(plotdata_3) + labs(title = models[3]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi3, digits = 4))))

mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of association between NEO correlations and semantic distance
print("Test of association between NEO correlations and semantic distances")
corrs <- pearscorr(scales, "NEOextra", pidtraits)
corrs$traitPID <- stringi::stri_sub(row.names(corrs), from = 4)
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_1, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_2, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_3, corrs, by = "traitPID")))

pf <- function(plotdata) {
  p <- baseplot(plotdata)
  p <- addneoline(p, plotdata, "NegativeAffect")
  p <- addneoline(p, plotdata, "Detachment")
  p <- p + labs(text = element_text(size = 16)) +
    geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE)
  p  
}
# the correlations are the same in all plotdata variables
crbound <- quantile(abs(plotdata_1$corrs), probs = 0.975)
csbound <- function(plotdata) {q <- quantile(plotdata$cosdist, probs=1-0.975); q}

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1, 
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3,
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of slopes significance in above plots
print("Tests of significance of slopes (prediction of response associations from semantic similarity")
pearscorr(plotdata_1 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_2 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_3 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1,
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3, 
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

```

All three models agree on the relationship between extraversion and detachment. Note in particular that the item pairs with the lower semantic distance were the same across models.

In contrast, the relationship between extraversion and negative affect was not consistent between the LLMs. According to the OpenAI model, the correlations invert in sign with larger semantic distance, a symptom of a heterogeneous relationship.

### Conscientiousness

```{r conscientiousness, message = FALSE}
plotdata_1 <- filter(cordata_1, typeNEO == "Conscientiousness")
plotdata_2 <- filter(cordata_2, typeNEO == "Conscientiousness")
plotdata_3 <- filter(cordata_3, typeNEO == "Conscientiousness")

# test of variance to see if semantic distance differs in PID traits
print("Omnibus test of differences in distances NEO/PID")
chi1 <- anovadist(plotdata_1)$Chisq[2]
chi2 <- anovadist(plotdata_2)$Chisq[2]
chi3 <- anovadist(plotdata_3)$Chisq[2]

p1 <- bxplf(plotdata_1) + labs(title = models[1]) + 
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi1, digits = 4))))
p2 <- bxplf(plotdata_2) + labs(title = models[2]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi2, digits = 4))))
p3 <- bxplf(plotdata_3) + labs(title = models[3]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi3, digits = 4))))

mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of association between NEO correlations and semantic distance
print("Test of association between NEO correlations and semantic distances")
corrs <- pearscorr(scales, "NEOgew", pidtraits)
corrs$traitPID <- stringi::stri_sub(row.names(corrs), from = 4)
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_1, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_2, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_3, corrs, by = "traitPID")))

pf <- function(plotdata) {
  p <- baseplot(plotdata)
  p <- addneoline(p, plotdata, "Anankastia")
  p <- addneoline(p, plotdata, "Disinhibition")
  p <- p + labs(text = element_text(size = 16)) +
    geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE)
  p  
}
# the correlations are the same in all plotdata variables
crbound <- quantile(abs(plotdata_1$corrs), probs = 0.975)
csbound <- function(plotdata) {q <- quantile(plotdata$cosdist, probs=1-0.975); q}

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1, 
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3,
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of slopes significance in above plots
print("Tests of significance of slopes (prediction of response associations from semantic similarity")
pearscorr(plotdata_1 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_2 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_3 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1,
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3, 
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

```

All models gave similar results in the analysis of consciousness, but the LLMs are more similar to each other that to the universal sentence encoder. All models agree on singling out the same two item pairs as being particularly semantically close (see text for discussion).

### Agreeableness

```{r agreeableness, message = FALSE}
plotdata_1 <- filter(cordata_1, typeNEO == "Agreeableness")
plotdata_2 <- filter(cordata_2, typeNEO == "Agreeableness")
plotdata_3 <- filter(cordata_3, typeNEO == "Agreeableness")

# test of variance to see if semantic distance differs in PID traits
print("Omnibus test of differences in distances NEO/PID")
chi1 <- anovadist(plotdata_1)$Chisq[2]
chi2 <- anovadist(plotdata_2)$Chisq[2]
chi3 <- anovadist(plotdata_3)$Chisq[2]

p1 <- bxplf(plotdata_1) + labs(title = models[1]) + 
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi1, digits = 4))))
p2 <- bxplf(plotdata_2) + labs(title = models[2]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi2, digits = 4))))
p3 <- bxplf(plotdata_3) + labs(title = models[3]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi3, digits = 4))))

mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of association between NEO correlations and semantic distance
print("Test of association between NEO correlations and semantic distances")
corrs <- pearscorr(scales, "NEOvertr", pidtraits)
corrs$traitPID <- stringi::stri_sub(row.names(corrs), from = 4)
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_1, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_2, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_3, corrs, by = "traitPID")))

pf <- function(plotdata) {
  p <- baseplot(plotdata)
  p <- addneoline(p, plotdata, "Psychoticism")
  p <- addneoline(p, plotdata, "Detachment")
  p <- addneoline(p, plotdata, "Antagonism")
  p <- p + labs(text = element_text(size = 16)) +
    geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE)
  p  
}
# the correlations are the same in all plotdata variables
crbound <- quantile(abs(plotdata_1$corrs), probs = 0.975)
csbound <- function(plotdata) {q <- quantile(plotdata$cosdist, probs=1-0.975); q}

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1, 
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3,
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of slopes significance in above plots
print("Tests of significance of slopes (prediction of response associations from semantic similarity")
pearscorr(plotdata_1 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_2 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_3 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1,
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3, 
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

```

The LLMs gave similar responses to the agreeableness dataset. Specifically, the steeper slope of the fits indicates a larger estimate of the relationship between semantic similarity and response correlations.

### Openness to experience

```{r openness, message = FALSE}
plotdata_1 <- filter(cordata_1, typeNEO == "Openness")
plotdata_2 <- filter(cordata_2, typeNEO == "Openness")
plotdata_3 <- filter(cordata_3, typeNEO == "Openness")

# test of variance to see if semantic distance differs in PID traits
print("Omnibus test of differences in distances NEO/PID")
chi1 <- anovadist(plotdata_1)$Chisq[2]
chi2 <- anovadist(plotdata_2)$Chisq[2]
chi3 <- anovadist(plotdata_3)$Chisq[2]

p1 <- bxplf(plotdata_1) + labs(title = models[1]) + 
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi1, digits = 4))))
p2 <- bxplf(plotdata_2) + labs(title = models[2]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi2, digits = 4))))
p3 <- bxplf(plotdata_3) + labs(title = models[3]) +
  xlab(bquote(chi[5]^2 ~ " = " ~ .(format(chi3, digits = 4))))

mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of association between NEO correlations and semantic distance
print("Test of association between NEO correlations and semantic distances")
corrs <- pearscorr(scales, "NEOoff", pidtraits)
corrs$traitPID <- stringi::stri_sub(row.names(corrs), from = 4)
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_1, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_2, corrs, by = "traitPID")))
summary(lmer(cosdist ~ abs(r) + (1 | itemNEO), left_join(plotdata_3, corrs, by = "traitPID")))

pf <- function(plotdata) {
  p <- baseplot(plotdata)
  p <- addneoline(p, plotdata, "Psychoticism")
  p <- addneoline(p, plotdata, "Detachment")
  p <- p + labs(text = element_text(size = 16)) +
    geom_hline(yintercept = 0, color = "darkgrey", show.legend = FALSE)
  p  
}
# the correlations are the same in all plotdata variables
crbound <- quantile(abs(plotdata_1$corrs), probs = 0.975)
csbound <- function(plotdata) {q <- quantile(plotdata$cosdist, probs=1-0.975); q}

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1, 
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3,
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = typePID), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

# test of slopes significance in above plots
print("Tests of significance of slopes (prediction of response associations from semantic similarity")
pearscorr(plotdata_1 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_2 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)
pearscorr(plotdata_3 |> select(traitPID, corrs, cosdist) |> pivot_wider(names_from = traitPID, values_from = cosdist), "corrs", traitnames)

p1 <- pf(plotdata_1) + 
        geom_text(data = filter(plotdata_1,
                                cosdist < csbound(plotdata_1) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[1])
p2 <- pf(plotdata_2) +
        geom_text(data = filter(plotdata_2, 
                                cosdist < csbound(plotdata_2) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[2])
p3 <- pf(plotdata_3) +
        geom_text(data = filter(plotdata_3, 
                                cosdist < csbound(plotdata_3) | abs(corrs) > crbound), 
              aes(label = paste(itemNEO, itemPID, sep=":")), alpha = 0.4) + 
        labs(title = models[3])
mp <- ggarrange(p1, p2, p3, ncol=3, nrow=1, common.legend = TRUE, legend = "right")
mp

```

The analysis of the openness to experience data gave fairly concordant results in the three datasets. However, OpenAI appears to have performed slightly better than gecko, as one can see from the fact that the middle of left side of the plot is emptier. gecko also estimates the semantic similarity between openness to experience and psychoticism to be lower than the other two models. Detachment may present some degree of heterogeneity in the association with openness to experience, as we see a mixture of positive and negative associations at low semantic distances. However, this may also be due to the failure of the language model to see as different items that gave very low correlations in the responses, although the two LLMs give almost identical estimates of similarity.


